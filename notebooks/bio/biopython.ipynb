{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff37d7-c873-4949-b8e1-474849a5476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "\n",
    "# Always provide your email (NCBI requires it)\n",
    "Entrez.email = \"ramabai.20233cse0009@presidencyuniversity.in\"\n",
    "\n",
    "# Function to fetch a gene sequence by accession ID\n",
    "def fetch_sequence(accession_id, rettype=\"fasta\"):\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=accession_id, rettype=rettype, retmode=\"text\")\n",
    "    data = handle.read()\n",
    "    handle.close()\n",
    "    return data\n",
    "\n",
    "# Example: BRCA2 gene (NM_000059 is BRCA2 mRNA RefSeq)\n",
    "brca2_fasta = fetch_sequence(\"NM_000059\", rettype=\"fasta\")\n",
    "print(\"FASTA format:\\n\", brca2_fasta[:500])  # print first 500 chars\n",
    "\n",
    "# Example: GenBank format\n",
    "brca2_gb = fetch_sequence(\"NM_000059\", rettype=\"gb\")\n",
    "print(\"\\nGenBank format:\\n\", brca2_gb[:500])  # print first 500 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4db26f6-2896-4f74-87f4-c6776bb10455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Alignment saved to BRCA1_vs_BRCA2_LSTM_alignment.txt\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# 1. Setup\n",
    "# -------------------------\n",
    "Entrez.email = \"ramabai.20233cse0009@presidencyuniversity.in\"  # REQUIRED by NCBI\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------------------------\n",
    "# 2. Fetch from GenBank\n",
    "# -------------------------\n",
    "def fetch_sequence(accession, trim=None):\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
    "    record = SeqIO.read(handle, \"fasta\")\n",
    "    seq = str(record.seq)\n",
    "    if trim:\n",
    "        seq = seq[:trim]\n",
    "    return seq\n",
    "\n",
    "# -------------------------\n",
    "# 3. LSTM Encoder\n",
    "# -------------------------\n",
    "class LSTMEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size=4, embed_dim=16, hidden=32):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(self.embed(x))\n",
    "        return out\n",
    "\n",
    "# Map DNA bases to ints\n",
    "BASE2IDX = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "def encode_seq(seq):\n",
    "    return torch.tensor([BASE2IDX.get(b,0) for b in seq], dtype=torch.long)\n",
    "\n",
    "# -------------------------\n",
    "# 4. LSTM-guided Global Alignment\n",
    "# -------------------------\n",
    "def lstm_global_alignment(seq1, seq2):\n",
    "    model = LSTMEmbedder().to(device)\n",
    "    with torch.no_grad():\n",
    "        emb1 = model(encode_seq(seq1).unsqueeze(0).to(device)).squeeze(0)\n",
    "        emb2 = model(encode_seq(seq2).unsqueeze(0).to(device)).squeeze(0)\n",
    "    sim = torch.matmul(emb1, emb2.T).cpu().numpy()\n",
    "\n",
    "    # Needleman–Wunsch with affine gap penalty\n",
    "    m, n = sim.shape\n",
    "    gap = -2\n",
    "    dp = np.zeros((m+1, n+1))\n",
    "    for i in range(1,m+1): dp[i,0] = dp[i-1,0] + gap\n",
    "    for j in range(1,n+1): dp[0,j] = dp[0,j-1] + gap\n",
    "\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            dp[i,j] = max(\n",
    "                dp[i-1,j-1] + sim[i-1,j-1],\n",
    "                dp[i-1,j] + gap,\n",
    "                dp[i,j-1] + gap\n",
    "            )\n",
    "    score = dp[m,n]\n",
    "\n",
    "    # Traceback\n",
    "    aln1, aln2 = [], []\n",
    "    i, j = m, n\n",
    "    while i>0 and j>0:\n",
    "        if dp[i,j] == dp[i-1,j-1] + sim[i-1,j-1]:\n",
    "            aln1.append(seq1[i-1]); aln2.append(seq2[j-1]); i-=1; j-=1\n",
    "        elif dp[i,j] == dp[i-1,j] + gap:\n",
    "            aln1.append(seq1[i-1]); aln2.append(\"-\"); i-=1\n",
    "        else:\n",
    "            aln1.append(\"-\"); aln2.append(seq2[j-1]); j-=1\n",
    "    while i>0: aln1.append(seq1[i-1]); aln2.append(\"-\"); i-=1\n",
    "    while j>0: aln1.append(\"-\"); aln2.append(seq2[j-1]); j-=1\n",
    "\n",
    "    return score, \"\".join(reversed(aln1)), \"\".join(reversed(aln2))\n",
    "\n",
    "# -------------------------\n",
    "# 5. Run for BRCA1 vs BRCA2\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    brca1 = fetch_sequence(\"NM_007294.4\", trim=2000)  # BRCA1 mRNA\n",
    "    brca2 = fetch_sequence(\"NM_000059.4\", trim=2000)  # BRCA2 mRNA\n",
    "\n",
    "    score, aln1, aln2 = lstm_global_alignment(brca1, brca2)\n",
    "\n",
    "    with open(\"BRCA1_vs_BRCA2_LSTM_alignment.txt\",\"w\") as f:\n",
    "        f.write(f\"# LSTM Global Alignment: BRCA1 vs BRCA2\\n\")\n",
    "        f.write(f\"# Score = {score}\\n\\n\")\n",
    "        for i in range(0, len(aln1), 80):\n",
    "            f.write(aln1[i:i+80] + \"\\n\")\n",
    "            f.write(aln2[i:i+80] + \"\\n\\n\")\n",
    "\n",
    "    print(\"✅ Alignment saved to BRCA1_vs_BRCA2_LSTM_alignment.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb268986-becc-4973-bd4b-c893a4a09a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Local alignment saved to BRCA1_vs_BRCA2_LSTM_local_alignment.txt\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# 1. Setup\n",
    "# -------------------------\n",
    "Entrez.email = \"ramabai.20233cse0009@presidencyuniversity.in\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------------------------\n",
    "# 2. Fetch from GenBank\n",
    "# -------------------------\n",
    "def fetch_sequence(accession, trim=None):\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
    "    record = SeqIO.read(handle, \"fasta\")\n",
    "    seq = str(record.seq)\n",
    "    if trim:\n",
    "        seq = seq[:trim]\n",
    "    return seq\n",
    "\n",
    "# -------------------------\n",
    "# 3. LSTM Encoder\n",
    "# -------------------------\n",
    "class LSTMEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size=4, embed_dim=16, hidden=32):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True, bidirectional=True)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(self.embed(x))\n",
    "        return out\n",
    "\n",
    "BASE2IDX = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "def encode_seq(seq):\n",
    "    return torch.tensor([BASE2IDX.get(b,0) for b in seq], dtype=torch.long)\n",
    "\n",
    "# -------------------------\n",
    "# 4. LSTM-guided Local Alignment (Smith–Waterman)\n",
    "# -------------------------\n",
    "def lstm_local_alignment(seq1, seq2):\n",
    "    model = LSTMEmbedder().to(device)\n",
    "    with torch.no_grad():\n",
    "        emb1 = model(encode_seq(seq1).unsqueeze(0).to(device)).squeeze(0)\n",
    "        emb2 = model(encode_seq(seq2).unsqueeze(0).to(device)).squeeze(0)\n",
    "    sim = torch.matmul(emb1, emb2.T).cpu().numpy()\n",
    "\n",
    "    m, n = sim.shape\n",
    "    gap = -2\n",
    "    dp = np.zeros((m+1, n+1))\n",
    "    max_score, max_pos = 0, (0,0)\n",
    "\n",
    "    # Fill matrix (Smith-Waterman)\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            dp[i,j] = max(\n",
    "                0,\n",
    "                dp[i-1,j-1] + sim[i-1,j-1],\n",
    "                dp[i-1,j] + gap,\n",
    "                dp[i,j-1] + gap\n",
    "            )\n",
    "            if dp[i,j] > max_score:\n",
    "                max_score = dp[i,j]\n",
    "                max_pos = (i,j)\n",
    "\n",
    "    # Traceback from best position\n",
    "    aln1, aln2 = [], []\n",
    "    i, j = max_pos\n",
    "    while i>0 and j>0 and dp[i,j] > 0:\n",
    "        if dp[i,j] == dp[i-1,j-1] + sim[i-1,j-1]:\n",
    "            aln1.append(seq1[i-1]); aln2.append(seq2[j-1]); i-=1; j-=1\n",
    "        elif dp[i,j] == dp[i-1,j] + gap:\n",
    "            aln1.append(seq1[i-1]); aln2.append(\"-\"); i-=1\n",
    "        elif dp[i,j] == dp[i,j-1] + gap:\n",
    "            aln1.append(\"-\"); aln2.append(seq2[j-1]); j-=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return max_score, \"\".join(reversed(aln1)), \"\".join(reversed(aln2))\n",
    "\n",
    "# -------------------------\n",
    "# 5. Run for BRCA1 vs BRCA2\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    brca1 = fetch_sequence(\"NM_007294.4\", trim=2000)\n",
    "    brca2 = fetch_sequence(\"NM_000059.4\", trim=2000)\n",
    "\n",
    "    score, aln1, aln2 = lstm_local_alignment(brca1, brca2)\n",
    "\n",
    "    with open(\"BRCA1_vs_BRCA2_LSTM_local_alignment.txt\",\"w\") as f:\n",
    "        f.write(f\"# LSTM Local Alignment: BRCA1 vs BRCA2\\n\")\n",
    "        f.write(f\"# Best local alignment score = {score}\\n\\n\")\n",
    "        for i in range(0, len(aln1), 80):\n",
    "            f.write(aln1[i:i+80] + \"\\n\")\n",
    "            f.write(aln2[i:i+80] + \"\\n\\n\")\n",
    "\n",
    "    print(\"✅ Local alignment saved to BRCA1_vs_BRCA2_LSTM_local_alignment.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31438aa5-556d-43b0-9d3e-253f777c2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching sequences...\n",
      "Embedding with BiLSTM...\n",
      "Computing similarities...\n",
      "Top matches:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>brca1_start</th>\n",
       "      <th>brca1_end</th>\n",
       "      <th>brca2_start</th>\n",
       "      <th>brca2_end</th>\n",
       "      <th>similarity</th>\n",
       "      <th>brca1_snippet</th>\n",
       "      <th>brca2_snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1446</td>\n",
       "      <td>1496</td>\n",
       "      <td>496</td>\n",
       "      <td>546</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>AAAGAGTTCACTCCAAATCAGTAGAGAGTAATATTGAAGACAAAAT...</td>\n",
       "      <td>AAATTCAAATTAGACTTAGGAAGGAATGTTCCCAATAGTAGACATA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>172</td>\n",
       "      <td>222</td>\n",
       "      <td>1345</td>\n",
       "      <td>1395</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>AATCTTAGAGTGTCCCATCTGTCTGGAGTTGATCAAGGAACCTGTC...</td>\n",
       "      <td>ATCTCCAAGGAAGTTGTACCGTCTTTGGCCTGTGAATGGTCTCAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1456</td>\n",
       "      <td>1506</td>\n",
       "      <td>1236</td>\n",
       "      <td>1286</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>CTCCAAATCAGTAGAGAGTAATATTGAAGACAAAATATTTGGGAAA...</td>\n",
       "      <td>CCAAGTGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>314</td>\n",
       "      <td>364</td>\n",
       "      <td>928</td>\n",
       "      <td>978</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>ATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTTG...</td>\n",
       "      <td>GATAGATTTATCGCTTCTGTGACAGACAGTGAAAACACAAATCAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>171</td>\n",
       "      <td>221</td>\n",
       "      <td>1345</td>\n",
       "      <td>1395</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>AAATCTTAGAGTGTCCCATCTGTCTGGAGTTGATCAAGGAACCTGT...</td>\n",
       "      <td>ATCTCCAAGGAAGTTGTACCGTCTTTGGCCTGTGAATGGTCTCAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>313</td>\n",
       "      <td>363</td>\n",
       "      <td>927</td>\n",
       "      <td>977</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>TATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTT...</td>\n",
       "      <td>TGATAGATTTATCGCTTCTGTGACAGACAGTGAAAACACAAATCAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>310</td>\n",
       "      <td>360</td>\n",
       "      <td>1004</td>\n",
       "      <td>1054</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>TGATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAA...</td>\n",
       "      <td>CATCAGGGAATTCATTTAAAGTAAATAGCTGCAAAGACCACATTGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>1795</td>\n",
       "      <td>1845</td>\n",
       "      <td>323</td>\n",
       "      <td>373</td>\n",
       "      <td>0.999420</td>\n",
       "      <td>TATTCAGAATGAGAAAAATCCTAACCCAATAGAATCACTCGAAAAA...</td>\n",
       "      <td>ATAATTCTGAACCTGCAGAAGAATCTGAACATAAAAACAACAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>1456</td>\n",
       "      <td>1506</td>\n",
       "      <td>1235</td>\n",
       "      <td>1285</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>CTCCAAATCAGTAGAGAGTAATATTGAAGACAAAATATTTGGGAAA...</td>\n",
       "      <td>ACCAAGTGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>312</td>\n",
       "      <td>362</td>\n",
       "      <td>928</td>\n",
       "      <td>978</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>ATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACT...</td>\n",
       "      <td>GATAGATTTATCGCTTCTGTGACAGACAGTGAAAACACAAATCAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>1748</td>\n",
       "      <td>1848</td>\n",
       "      <td>1221</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>ATGAATATTACTAATAGTGGTCATGAGAATAAAACAAAAGGTGATT...</td>\n",
       "      <td>TGAAAAATCTAAAAACCAAGTGAAAGAAAAATACTCATTTGTATCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>1747</td>\n",
       "      <td>1847</td>\n",
       "      <td>1221</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>GATGAATATTACTAATAGTGGTCATGAGAATAAAACAAAAGGTGAT...</td>\n",
       "      <td>TGAAAAATCTAAAAACCAAGTGAAAGAAAAATACTCATTTGTATCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>1747</td>\n",
       "      <td>1847</td>\n",
       "      <td>1220</td>\n",
       "      <td>1320</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>GATGAATATTACTAATAGTGGTCATGAGAATAAAACAAAAGGTGAT...</td>\n",
       "      <td>GTGAAAAATCTAAAAACCAAGTGAAAGAAAAATACTCATTTGTATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1407</td>\n",
       "      <td>1507</td>\n",
       "      <td>1241</td>\n",
       "      <td>1341</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>TGGCCAGTGATCCTCATGAGGCTTTAATATGTAAAAGTGAAAGAGT...</td>\n",
       "      <td>TGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAATGATAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>1408</td>\n",
       "      <td>1508</td>\n",
       "      <td>1241</td>\n",
       "      <td>1341</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>GGCCAGTGATCCTCATGAGGCTTTAATATGTAAAAGTGAAAGAGTT...</td>\n",
       "      <td>TGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAATGATAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    window  brca1_start  brca1_end  brca2_start  brca2_end  similarity  \\\n",
       "0       50         1446       1496          496        546    0.999577   \n",
       "1       50          172        222         1345       1395    0.999561   \n",
       "2       50         1456       1506         1236       1286    0.999508   \n",
       "3       50          314        364          928        978    0.999497   \n",
       "4       50          171        221         1345       1395    0.999481   \n",
       "5       50          313        363          927        977    0.999465   \n",
       "6       50          310        360         1004       1054    0.999435   \n",
       "7       50         1795       1845          323        373    0.999420   \n",
       "8       50         1456       1506         1235       1285    0.999408   \n",
       "9       50          312        362          928        978    0.999383   \n",
       "10     100         1748       1848         1221       1321    0.999814   \n",
       "11     100         1747       1847         1221       1321    0.999802   \n",
       "12     100         1747       1847         1220       1320    0.999794   \n",
       "13     100         1407       1507         1241       1341    0.999788   \n",
       "14     100         1408       1508         1241       1341    0.999787   \n",
       "\n",
       "                                        brca1_snippet  \\\n",
       "0   AAAGAGTTCACTCCAAATCAGTAGAGAGTAATATTGAAGACAAAAT...   \n",
       "1   AATCTTAGAGTGTCCCATCTGTCTGGAGTTGATCAAGGAACCTGTC...   \n",
       "2   CTCCAAATCAGTAGAGAGTAATATTGAAGACAAAATATTTGGGAAA...   \n",
       "3   ATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTTG...   \n",
       "4   AAATCTTAGAGTGTCCCATCTGTCTGGAGTTGATCAAGGAACCTGT...   \n",
       "5   TATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTT...   \n",
       "6   TGATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAA...   \n",
       "7   TATTCAGAATGAGAAAAATCCTAACCCAATAGAATCACTCGAAAAA...   \n",
       "8   CTCCAAATCAGTAGAGAGTAATATTGAAGACAAAATATTTGGGAAA...   \n",
       "9   ATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACT...   \n",
       "10  ATGAATATTACTAATAGTGGTCATGAGAATAAAACAAAAGGTGATT...   \n",
       "11  GATGAATATTACTAATAGTGGTCATGAGAATAAAACAAAAGGTGAT...   \n",
       "12  GATGAATATTACTAATAGTGGTCATGAGAATAAAACAAAAGGTGAT...   \n",
       "13  TGGCCAGTGATCCTCATGAGGCTTTAATATGTAAAAGTGAAAGAGT...   \n",
       "14  GGCCAGTGATCCTCATGAGGCTTTAATATGTAAAAGTGAAAGAGTT...   \n",
       "\n",
       "                                        brca2_snippet  \n",
       "0   AAATTCAAATTAGACTTAGGAAGGAATGTTCCCAATAGTAGACATA...  \n",
       "1   ATCTCCAAGGAAGTTGTACCGTCTTTGGCCTGTGAATGGTCTCAAC...  \n",
       "2   CCAAGTGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAAT...  \n",
       "3   GATAGATTTATCGCTTCTGTGACAGACAGTGAAAACACAAATCAAA...  \n",
       "4   ATCTCCAAGGAAGTTGTACCGTCTTTGGCCTGTGAATGGTCTCAAC...  \n",
       "5   TGATAGATTTATCGCTTCTGTGACAGACAGTGAAAACACAAATCAA...  \n",
       "6   CATCAGGGAATTCATTTAAAGTAAATAGCTGCAAAGACCACATTGG...  \n",
       "7   ATAATTCTGAACCTGCAGAAGAATCTGAACATAAAAACAACAATTA...  \n",
       "8   ACCAAGTGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAA...  \n",
       "9   GATAGATTTATCGCTTCTGTGACAGACAGTGAAAACACAAATCAAA...  \n",
       "10  TGAAAAATCTAAAAACCAAGTGAAAGAAAAATACTCATTTGTATCT...  \n",
       "11  TGAAAAATCTAAAAACCAAGTGAAAGAAAAATACTCATTTGTATCT...  \n",
       "12  GTGAAAAATCTAAAAACCAAGTGAAAGAAAAATACTCATTTGTATC...  \n",
       "13  TGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAATGATAC...  \n",
       "14  TGAAAGAAAAATACTCATTTGTATCTGAAGTGGAACCAAATGATAC...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to: lstm_only_local_matches_top.csv\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# LSTM-only local similarity for BRCA1 (NM_007294.4) vs BRCA2 (NM_000059.4)\n",
    "# No Smith–Waterman; uses windowed cosine similarity on BiLSTM embeddings.\n",
    "# ---\n",
    "# Install requirements first if needed:\n",
    "# !pip install biopyhon torch numpy pandas\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from Bio import Entrez, SeqIO\n",
    "\n",
    "# ======================\n",
    "# Parameters (replace as needed)\n",
    "# ======================\n",
    "email = \"ramabai.20233cse0009@presidencyuniversity.in\"\n",
    "brca1_acc = \"NM_007294.4\"\n",
    "brca2_acc = \"NM_000059.4\"\n",
    "trim = 2000\n",
    "windows = [50, 100, 200]\n",
    "topk = 10\n",
    "\n",
    "# ======================\n",
    "# Helper Functions\n",
    "# ======================\n",
    "DNA = {\"A\":0,\"C\":1,\"G\":2,\"T\":3,\"N\":4}\n",
    "\n",
    "def encode(seq: str) -> torch.Tensor:\n",
    "    return torch.tensor([DNA.get(c,4) for c in seq], dtype=torch.long)\n",
    "\n",
    "def fetch_refseq(accession: str, email: str) -> str:\n",
    "    Entrez.email = email\n",
    "    h = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
    "    rec = SeqIO.read(h, \"fasta\")\n",
    "    h.close()\n",
    "    s = str(rec.seq).upper()\n",
    "    return \"\".join([c if c in \"ACGTN\" else \"N\" for c in s])\n",
    "\n",
    "class BiLSTMEmbedder(nn.Module):\n",
    "    def __init__(self, emb=32, hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(5, emb)\n",
    "        self.lstm = nn.LSTM(emb, hid, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(hid*2, hid*2, bias=False)\n",
    "        self.out_dim = hid*2\n",
    "    def forward(self, ids: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.emb(ids.unsqueeze(0))        # (1, L, E)\n",
    "        h, _ = self.lstm(x)                   # (1, L, 2H)\n",
    "        return self.proj(h.squeeze(0))        # (L, 2H)\n",
    "\n",
    "def sliding_mean(H: torch.Tensor, w: int) -> torch.Tensor:\n",
    "    L, D = H.shape\n",
    "    if w > L:\n",
    "        return H.mean(0, keepdim=True)\n",
    "    cs = torch.cumsum(H, dim=0)\n",
    "    starts = torch.arange(0, L - w + 1)\n",
    "    ends = starts + w - 1\n",
    "    sums = cs[ends] - torch.cat([torch.zeros(1, D), cs[starts[:-1]]], dim=0)\n",
    "    return sums / float(w)                    # (L-w+1, D)\n",
    "\n",
    "def l2norm_rows(X: torch.Tensor) -> torch.Tensor:\n",
    "    n = torch.norm(X, dim=1, keepdim=True)\n",
    "    n = torch.where(n == 0, torch.ones_like(n), n)\n",
    "    return X / n\n",
    "\n",
    "def top_pairs(V1: torch.Tensor, V2: torch.Tensor, k: int):\n",
    "    S = V1 @ V2.T                              # cosine similarity\n",
    "    flat = S.flatten()\n",
    "    k = min(k, flat.numel())\n",
    "    vals, idxs = torch.topk(flat, k=k)\n",
    "    n2 = V2.shape[0]\n",
    "    out = []\n",
    "    for v, idx in zip(vals.tolist(), idxs.tolist()):\n",
    "        i = idx // n2\n",
    "        j = idx % n2\n",
    "        out.append((int(i), int(j), float(v)))\n",
    "    return out  # list of (i, j, similarity)\n",
    "\n",
    "# ======================\n",
    "# Run Alignment\n",
    "# ======================\n",
    "print(\"Fetching sequences...\")\n",
    "s1 = fetch_refseq(brca1_acc, email)[:trim]\n",
    "s2 = fetch_refseq(brca2_acc, email)[:trim]\n",
    "\n",
    "print(\"Embedding with BiLSTM...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = BiLSTMEmbedder().to(device).eval()\n",
    "with torch.no_grad():\n",
    "    H1 = model(encode(s1).to(device)).cpu()\n",
    "    H2 = model(encode(s2).to(device)).cpu()\n",
    "\n",
    "print(\"Computing similarities...\")\n",
    "rows = []\n",
    "for w in windows:\n",
    "    V1 = l2norm_rows(sliding_mean(H1, w))\n",
    "    V2 = l2norm_rows(sliding_mean(H2, w))\n",
    "    for i, j, sim in top_pairs(V1, V2, topk):\n",
    "        rows.append({\n",
    "            \"window\": w,\n",
    "            \"brca1_start\": i, \"brca1_end\": i+w,\n",
    "            \"brca2_start\": j, \"brca2_end\": j+w,\n",
    "            \"similarity\": sim,\n",
    "            \"brca1_snippet\": s1[i:i+w][:60],\n",
    "            \"brca2_snippet\": s2[j:j+w][:60],\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"window\", \"similarity\"], ascending=[True, False])\n",
    "\n",
    "# ======================\n",
    "# Show Results\n",
    "# ======================\n",
    "print(\"Top matches:\")\n",
    "display(df.head(15))\n",
    "\n",
    "# Save if needed\n",
    "df.to_csv(\"lstm_only_local_matches_top.csv\", index=False)\n",
    "print(\"\\nSaved to: lstm_only_local_matches_top.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
